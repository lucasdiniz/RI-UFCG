{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "EMPTY_LIST  = []\n",
    "TITLE = 1\n",
    "SUBTITLE = 2\n",
    "CONTENT = 3\n",
    "URL = 4\n",
    "ID = 5\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 1 - Escreva uma função que receba uma coleção de documentos e retorne uma matrix de termos-termos contendo as frequências de co-ocorrência de duas palavras consecutivas no texto (bigramas).\n",
    "\n",
    "Primeiramente escreveremos uma função que retorna uma lista em que cada elemento é uma palavra de um documento do corpus. Para melhorar o processo iremos utilizar o stopwords do nltk para eliminar termos indesejados tais como conjunções, preposições e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getTokens():\n",
    "    data_frame = pd.read_csv('estadao_noticias_eleicao.csv')\n",
    "    data = (data_frame.titulo + \" \" + data_frame.subTitulo + \" \" + data_frame.conteudo).fillna(\"\")\n",
    "    stopword_ = stopwords.words('portuguese')\n",
    "    data = data \\\n",
    "            .apply( \\\n",
    "                    lambda text: \\\n",
    "                        tokenizer.tokenize(text.lower()) \\\n",
    "            ).apply( \\\n",
    "                    lambda tokens: \\\n",
    "                        [d for d in tokens if d not in stopword_] \\\n",
    "            )\n",
    "    data = [ el for row in data for el in row ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizaremos o código disponibilizado [aqui](https://github.com/allansales/information-retrieval/blob/master/Lab%202/coocurrence_matrix.ipynb) para obter nossa matriz de termos-termos com a frequência de bigramas em todo o corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from co_ocurrence import co_occurrence_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 2 - Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorneas top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palavras que mais co-ocorrem com computador = [['youssef', 4], ['filho', 2], ['prefeitura', 2]]\n",
      "palavras que mais co-ocorrem com dinheiro = [['público', 105], ['é', 28], ['vivo', 26]]\n",
      "palavras que mais co-ocorrem com governo = [['federal', 672], ['dilma', 514], ['estado', 314]]\n"
     ]
    }
   ],
   "source": [
    "def top_n(word, n):\n",
    "    global term_term_matrix, vocab\n",
    "    word = word.lower()\n",
    "    if word not in vocab.keys(): \n",
    "        return []\n",
    "    matches = [[w1, consultable_matrix[vocab[word], vocab[w1]]] for w1 in vocab if consultable_matrix[vocab[word], vocab[w1]] > 0]\n",
    "    result = sorted(matches, key= lambda x:x[1], reverse=True)\n",
    "    return result[:n]\n",
    "\n",
    "words = getTokens()\n",
    "term_term_matrix, vocab = co_occurrence_matrix(words)\n",
    "global consultable_matrix\n",
    "consultable_matrix = term_term_matrix.tocsr()\n",
    "\n",
    "query_1 = \"computador\"\n",
    "query_2 = \"dinheiro\"\n",
    "query_3 = \"governo\"\n",
    "\n",
    "print(\"palavras que mais co-ocorrem com {0} = {1}\".format(query_1, top_n(query_1, 3))) \n",
    "print(\"palavras que mais co-ocorrem com {0} = {1}\".format(query_2, top_n(query_2, 3)))\n",
    "print(\"palavras que mais co-ocorrem com {0} = {1}\".format(query_3, top_n(query_3, 3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 3 - Expanda a consulta original com os termos retornados no passo 2 acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'computador youssef filho prefeitura'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def getWords(top_n_list):\n",
    "    return [word_frequency[0] for word_frequency in top_n_list]\n",
    "\n",
    "def expandQuery(query):\n",
    "    newQuery = list(chain.from_iterable([t, *getWords(top_n(t, 3))]for t in tokenizer.tokenize(query.lower())))\n",
    "    return newQuery\n",
    "\n",
    "\" \".join(expandQuery(\"computador\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os termos retornados não parecem ter muita relação com a palavra chave original, contudo, isso é de se esperar visto que estamos tratando apenas com notícias sobre política. É válido notar também que os termos que mais co-ocorrem com computador tem uma frequência baixa devido ao termo 'COMPUTADOR' não ser muito relevante no contexto de política."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 4 - Faça uma busca disjuntiva (OR) considerando a nova consulta.\n",
    "\n",
    "A busca disjuntiva dos termos foi feita considerando a estratégia de ordenação TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inverted_index import inverted_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Título: Motociclistas abastecem de graça em cidade maranhense que recebeu comícios de Lobão Filho \n",
      "Sub-título: Aliada de candidato no Maranhão dá gasolina a eleitores\n",
      "URL: http://politica.estadao.com.br/noticias/eleicoes,motociclistas-abastecem-de-graca-em-cidade-maranhense-que-recebeu-comicios-de-lobao-filho,1569953\n",
      "\n",
      "Título: A Aécio, DEM reforça decisão de manter candidatura própria no Rio\n",
      "Sub-título: Lideranças de partido aliado do PSDB recusam proposta de pré-candidato tucano de apoiar reeleição de Luiz Fernando Pezão (PMDB)\n",
      "URL: http://politica.estadao.com.br/noticias/geral,a-aecio-dem-reforca-decisao-de-manter-candidatura-propria-no-rio,1510723\n",
      "\n",
      "Título: Paes reforça tese de candidatura própria do PMDB à Presidência, mas diz que agora é preciso ajudar Dilma\n",
      "Sub-título: Reeleito em 2012 com 65% dos votos, prefeito do Rio não estimula as especulações de que poderá disputar o Planalto\n",
      "URL: http://politica.estadao.com.br/noticias/geral,paes-reforca-tese-de-candidatura-propria-do-pmdb-a-presidencia-mas-diz-que-agora-e-preciso-ajudar-dilma,1585114\n",
      "\n",
      "Título: Mais Médicos motiva entrada de entidades na campanha\n",
      "Sub-título: Em ao menos 10 Estados, profissionais fazem atos contra reeleição de Dilma ou divulgam críticas ao governo federal\n",
      "URL: http://politica.estadao.com.br/noticias/eleicoes,mais-medicos-motiva-entrada-de-entidades-na-campanha,1576902\n",
      "\n",
      "Título: Para Dilma, inflação está sob controle\n",
      "Sub-título: A presidente disse que, enquanto no resto do mundo, a partir de 2008, 60 milhões de pessoas perderam o emprego, no Brasil 1,5 milhão entrou no mercado de trabalho\n",
      "URL: http://politica.estadao.com.br/noticias/geral,para-dilma-inflacao-esta-sob-controle,1537829\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = inverted_index()\n",
    "query_result = idx.searchOr(\" \".join(expandQuery(\"computador\")))\n",
    "final_result = idx.getArticles(query_result)\n",
    "for article in final_result:\n",
    "    print('Título: {0}'.format(article[TITLE]))\n",
    "    print('Sub-título: {0}'.format(article[SUBTITLE]))\n",
    "    print('URL: {0}\\n'.format(article[URL]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A estratégia de expansão de consultas parece ser mais apropriada para aumentar o recall pois o resultado das consultas irá incluir também termos de outros documentos. Contudo, o maior número de documentos não relacionados com a consulta pode acabar por diminuir o precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
