{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "EMPTY_LIST  = []\n",
    "TITLE = 1\n",
    "SUBTITLE = 2\n",
    "CONTENT = 3\n",
    "URL = 4\n",
    "ID = 5\n",
    "\n",
    "tokenizer = RegexpTokenizer(r'\\w+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 1 - Escreva uma função que receba uma coleção de documentos e retorne uma matrix de termos-termos contendo as frequências de co-ocorrência de duas palavras consecutivas no texto (bigramas).\n",
    "\n",
    "Primeiramente escreveremos uma função que retorna uma lista em que cada elemento é uma palavra de um documento do corpus. Para melhorar o processo iremos utilizar o stopwords do nltk para eliminar termos indesejados tais como conjunções, preposições e etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getWords():\n",
    "    data_frame = pd.read_csv('estadao_noticias_eleicao.csv')\n",
    "    data = (data_frame.titulo + \" \" + data_frame.subTitulo + \" \" + data_frame.conteudo).fillna(\"\")\n",
    "    stopword_ = stopwords.words('portuguese')\n",
    "    data = data \\\n",
    "            .apply( \\\n",
    "                    lambda text: \\\n",
    "                        tokenizer.tokenize(text.lower()) \\\n",
    "            ).apply( \\\n",
    "                    lambda tokens: \\\n",
    "                        [d for d in tokens if d not in stopword_] \\\n",
    "            )\n",
    "    data = [ el for row in data for el in row ]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora utilizaremos o código disponibilizado [aqui](https://github.com/allansales/information-retrieval/blob/master/Lab%202/coocurrence_matrix.ipynb) para obter nossa matriz de termos-termos com a frequência de bigramas em todo o corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from co_ocurrence import co_occurrence_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 2 - Escreva uma função que receba um certo termo de consulta e a matriz construída no passo 1 acima e retorneas top-3 palavras em ordem decrescente de frequencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "palavras que mais co-ocorrem com corrupção = [['petrobrás', 109], ['ativa', 53], ['passiva', 51]]\n",
      "palavras que mais co-ocorrem com dinheiro = [['público', 105], ['é', 28], ['vivo', 26]]\n",
      "palavras que mais co-ocorrem com governo = [['federal', 672], ['dilma', 514], ['estado', 314]]\n"
     ]
    }
   ],
   "source": [
    "def top_n(word, n):\n",
    "    global term_term_matrix, vocab\n",
    "    word = word.lower()\n",
    "    if word not in vocab.keys(): \n",
    "        return []\n",
    "    matches = [[w1, usable_matrix[vocab[word], vocab[w1]]] for w1 in vocab if usable_matrix[vocab[word], vocab[w1]] > 0]\n",
    "    result = sorted(matches, key= lambda x:x[1], reverse=True)\n",
    "    return result[:n]\n",
    "\n",
    "words = readData()\n",
    "term_term_matrix, vocab = co_occurrence_matrix(words)\n",
    "consultable_matrix = term_term_matrix.tocsr()\n",
    "\n",
    "query_1 = \"corrupção\"\n",
    "query_2 = \"dinheiro\"\n",
    "query_3 = \"governo\"\n",
    "\n",
    "print(\"palavras que mais co-ocorrem com {0} = {1}\".format(query_1, top_n(query_1, 3))) \n",
    "print(\"palavras que mais co-ocorrem com {0} = {1}\".format(query_2, top_n(query_2, 3)))\n",
    "print(\"palavras que mais co-ocorrem com {0} = {1}\".format(query_3, top_n(query_3, 3)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item 3 - Expanda a consulta original com os termos retornados no passo 2 acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'estado governo dilma federal'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "def getWords(top_n_list):\n",
    "    return [word_frequency[0] for word_frequency in top_n_list]\n",
    "\n",
    "def expandQuery(query):\n",
    "    newQuery = list(chain.from_iterable([t, *getWords(top_n(t, 3))]for t in tokenizer.tokenize(query.lower())))\n",
    "    return \" \".join(set(newQuery))\n",
    "\n",
    "expandQuery(\"governo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
