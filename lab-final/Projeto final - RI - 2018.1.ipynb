{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise de sentimentos de tweets\n",
    "\n",
    "Nesta atividade iremos treinar um classificador capaz de determinar se um certo tweet é positivo ou negativo.\n",
    "\n",
    "Para isso iremos utilizar dados de tweets **EM PORTUGUÊS** já pré-rotulados através da presença de emoticons (carinha triste para negativo e carinha feliz para positivo). O dataset foi isponibilizados pelo monitor e pode ser encontrado [aqui](https://github.com/antonioricardojr/dataset).\n",
    "\n",
    "Etapas:\n",
    "\n",
    "1. Importação dos dados.\n",
    "2. Limpeza e tratamento dos dados.\n",
    "3. Separação dos dados em treino e teste.\n",
    "4. Treinamento do classificador.\n",
    "5. Obtendo tweets de uma hashtag e testando o classificador.\n",
    "\n",
    "### Importação dos dados\n",
    "\n",
    "Para importação dos dados que estão em formato csv usaremos a função read_csv do pandas, que já nos devolve os dados no formato de um dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pandas\n",
    "\n",
    "dados = pandas.read_csv('dados/db.csv',encoding='utf-8', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limpeza e tratamento dos dados\n",
    "\n",
    "Mesmo sem olhar os dados sabemos que existem algumas construções textuais que precisam ser removidas. Links, hashtags e referências a outros usuáris através do '@' são irrelevantes e devem ser removidos. Além disso, devemos remover também *stopwords* e símbolos de pontuação. Temos então a seguinte agenda:\n",
    "\n",
    "1. Remover links, hashtags e referencias a outros usuários\n",
    "2. Remover stopwords e símbolos de pontuação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from string import punctuation as pontuacao\n",
    "from collections import OrderedDict\n",
    "\n",
    "def remove_links_hashtags_referencias(texto):\n",
    "    texto = re.sub(r'http\\S+', '', texto)\n",
    "    texto = re.sub(r'@\\S+', '', texto)\n",
    "    texto = re.sub(r'#\\S+', '', texto)\n",
    "    return texto\n",
    "    \n",
    "def remove_stopwords_e_pontuacao(texto):\n",
    "    texto = remove_links_hashtags_referencias(texto)\n",
    "    tokens = nltk.word_tokenize(texto.lower())\n",
    "    stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "    return [palavra for palavra in tokens if palavra not in stopwords and palavra not in pontuacao]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separação dos dados em treino e teste.\n",
    "\n",
    "Antes de separar nossos dados é preciso decidir como será feita a extração de *features* dos *tweets*, nesse lab utilizaremos o modelo de *bag-of-words* onde iremos representar cada *tweet* como o conjuto de palavras pelo qual ele é composto.\n",
    "\n",
    "Com os *bags-of-words* em mãos podemos dividir nossos dados em treino e teste. Iremos utilizar um divisão de 60% dos dados para treino e 40% para teste do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtem_features(text): return dict([(word, True) for word in remove_stopwords_e_pontuacao(text)])\n",
    "\n",
    "negativos = [(obtem_features(row.text), 'negativo') for _, row in dados[dados.sentiment == 0].iterrows()]\n",
    "positivos = [(obtem_features(row.text), 'positivo') for _, row in dados[dados.sentiment == 1].iterrows()]\n",
    "\n",
    "\n",
    "threshold  = .6\n",
    "num_pos = int(threshold * len(positivos))\n",
    "num_neg = int(threshold * len(negativos))\n",
    "\n",
    "dados_treino = positivos[:num_pos] + negativos[:num_neg]\n",
    "dados_teste = positivos[num_pos:] + negativos[:num_neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do classificador\n",
    "\n",
    "Agora que já preparamos nossos dados podemos treinar nosso classificador utilizando a técnica *Naive Bayes*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy nos dados de teste: 0.86\n"
     ]
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier \n",
    "from nltk.classify.util import accuracy as nltk_acc\n",
    "\n",
    "classifier = NaiveBayesClassifier.train(dados_treino)\n",
    "print(u'\\nAccuracy nos dados de teste: {:.2f}'.format(nltk_acc(classifier, dados_teste)) )\n",
    "\n",
    "def classifica(texto):\n",
    "    probs = classifier.prob_classify(obtem_features(texto))\n",
    "    predicao = probs.max()\n",
    "    print(\"{:.02f}% {}\".format(probs.prob(predicao)*100, predicao.capitalize()) +  ' - ' + texto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features mais significativas\n",
    "\n",
    "Vejamos agora as 20 features(palavras) mais importantes para o classificador determinar o sentimento de um tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     foo = True           positi : negati =     70.6 : 1.0\n",
      "                      af = True           negati : positi =     39.3 : 1.0\n",
      "                    veja = True           positi : negati =     29.2 : 1.0\n",
      "                   breve = True           positi : negati =     26.7 : 1.0\n",
      "                   bravo = True           positi : negati =     25.4 : 1.0\n",
      "                   clube = True           positi : negati =     21.7 : 1.0\n",
      "                     vei = True           negati : positi =     21.6 : 1.0\n",
      "                   segui = True           positi : negati =     21.0 : 1.0\n",
      "                  adorei = True           positi : negati =     21.0 : 1.0\n",
      "                     bar = True           negati : positi =     19.9 : 1.0\n",
      "                     sdd = True           negati : positi =     19.7 : 1.0\n",
      "                 saudade = True           negati : positi =     18.0 : 1.0\n",
      "                  triste = True           negati : positi =     17.5 : 1.0\n",
      "                  equipe = True           positi : negati =     17.3 : 1.0\n",
      "                     sdv = True           positi : negati =     17.3 : 1.0\n",
      "                sofrendo = True           negati : positi =     16.6 : 1.0\n",
      "                 confira = True           positi : negati =     16.3 : 1.0\n",
      "                   valeu = True           positi : negati =     16.0 : 1.0\n",
      "                agradece = True           positi : negati =     15.4 : 1.0\n",
      "                   zeavy = True           positi : negati =     15.4 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O fato dos dados de treino terem sido obtidos e classificados e positivos através da presença de emoticons afetou bastante o treino do classificador. Muitas vezes uma carinha feliz no âmbito da internet pode denotar sarcasmo ou ironia com relação a algum fato *negativo*. A palavra 'bravo' é um exemplo disso, caso ela apareça um tweet este tem 25 vezes mais chances de ser *positivo*, algo no mínimo estranho para uma palavra que tem uma semântica inerentemente negativa.\n",
    "\n",
    "Vejamos um exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.70% Positivo - Hoje estou muito bravo, o dia foi horrível.\n",
      "71.20% Positivo - O clube de futebol São Paulo sofreu sua pior derrota da história\n"
     ]
    }
   ],
   "source": [
    "classifica('Hoje estou muito bravo, o dia foi horrível.')\n",
    "classifica('O clube de futebol São Paulo sofreu sua pior derrota da história')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contudo, nosso classificador parece se comportar como esperado em cenários específicos como:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.74% Negativo - Hoje eu vou para o bar beber ate passar a saudade dela.\n",
      "96.73% Positivo - Adorei o novo filme dos vingadores\n"
     ]
    }
   ],
   "source": [
    "classifica('Hoje eu vou para o bar beber ate passar a saudade dela.')\n",
    "classifica('Adorei o novo filme dos vingadores')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando o classificador com novos tweets\n",
    "\n",
    "Para testar o classificador eu obtive alguns tweets da hashtag [#LulaPreso](https://twitter.com/hashtag/lulapreso?lang=en). Vamos ver o que o nosso classificador tem a dizer sobre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.57% Negativo - #LulaLivre ? Só que não. Lula bom é lula morto, trocando em miúdos é uma apologia à corrupção e ao crime. A hashtag da vez deve ser #LulaPreso porque lugar de bandido é na cadeia\n",
      "67.29% Positivo - O MEU MOVIMENTO É: #LULAPRESO SE MANTER A JARARACA DENTRO DA GARRAFA DE CACHAÇA ELA NÃO MORDERÁ NINGUÉM E O BRASIL SERÁ FELIZ. \n",
      "92.98% Negativo - COM O MOLUSCO CACHACEIRO NA CADEIA A BOSTA DESSE PAÍS VAI PRA FRENTE #LULAPRESO\n"
     ]
    }
   ],
   "source": [
    "tweets = []\n",
    "\n",
    "tweets.append('#LulaLivre ? Só que não. Lula bom é lula morto, trocando em miúdos é uma apologia à corrupção e ao crime. A hashtag da vez deve ser #LulaPreso porque lugar de bandido é na cadeia')\n",
    "tweets.append('O MEU MOVIMENTO É: #LULAPRESO SE MANTER A JARARACA DENTRO DA GARRAFA DE CACHAÇA ELA NÃO MORDERÁ NINGUÉM E O BRASIL SERÁ FELIZ. ')\n",
    "tweets.append('COM O MOLUSCO CACHACEIRO NA CADEIA A BOSTA DESSE PAÍS VAI PRA FRENTE #LULAPRESO')\n",
    "\n",
    "for tweet in tweets:\n",
    "    classifica(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Considerações finais\n",
    "\n",
    "A abordagem utilizada para pré-classificar os dados de treino poderia ser mais robusta, talvez utilizando alguma alguma técnica de processamento de linguagem natural.\n",
    "\n",
    "Poderiamos usar um volume maior de dados para treinar pois assim palavras que tiveram resultados inesperados como 'bravo' possivelmente iriam tender ao seu real significado semântico.\n",
    "\n",
    "Ainda é possível aprimorar o pré-processamento dos textos dos tweets usando técnicas como *stemming* (reduzir verbos ao infinitivo é um exemplo). Nesse lab eu tentei utilizar o SnowballStemmer do nltk mas não obtive resultados satisfatórios.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
