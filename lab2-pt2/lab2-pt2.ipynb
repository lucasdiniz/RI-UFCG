{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura dos dados\n",
    "\n",
    "Nesse lab iremos trabalhar em um dataset que nos trás *ratings* referentes a notas atribuídas por investidores de bitcoins a outros investidores.  Para ilustrar o _rating_ iremos utilizar um grafo representado através de uma matriz de adjacência onde os vértices são os investidores e uma arestas entre representa que os vértice *origem* da aresta atribuiu uma nota ao vértice *destino*, contudo, consideraremos apenas as avaliações com nota maior ou igual a 8.\n",
    "\n",
    "Antes de começarmos temos que lidar com uma pequena limitação, nos dados originais **cada investidor possui um número único que o identifica e este pode chegar a um valor superior a 6500**, quando **no entanto existem apenas um pouco mais de 5800 investidores nos dados**. Quando limitamos os dados às notas maiores que **8.0** sobram apenas **915** desses investidores .\n",
    "\n",
    "Dito isto é fácil notar que não é apropriado utilizar o id do investidor que vem no dataset para indexar nossa matriz, para isto criamos algumas funções e variáveis auxiliares para ajudar na indexação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class PageRank():\n",
    "    def __init__(self):\n",
    "        self.N = 915\n",
    "        self.data_frame = pd.read_csv('dados/soc-sign-bitcoinotc.csv')\n",
    "        self.data_frame.columns = ['origem', 'destino', 'peso', 'tempo']\n",
    "        self.indice_original = {}\n",
    "        self.indice_matriz = {}\n",
    "        self.numero_de_links = {}\n",
    "        self.idx = 0\n",
    "        self.matriz_transferencia = np.zeros((self.N, self.N))\n",
    "        self.google_matriz = None\n",
    "\n",
    "\n",
    "    def get_indice_origem_destino(self, origem, destino):\n",
    "            if origem not in self.indice_matriz:\n",
    "                self.indice_matriz[origem] = self.idx\n",
    "                self.indice_original[self.idx] = origem\n",
    "                origem = self.idx\n",
    "                self.idx += 1\n",
    "            else:\n",
    "                origem = self.indice_matriz[origem]\n",
    "\n",
    "            if destino not in self.indice_matriz:\n",
    "                self.indice_matriz[destino] = self.idx\n",
    "                self.indice_original[self.idx] = destino\n",
    "                destino = self.idx\n",
    "                self.idx += 1\n",
    "            else:\n",
    "                destino = self.indice_matriz[destino]\n",
    "            return origem, destino"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a matriz de adjacência (matriz de transferência)\n",
    "\n",
    "Agora que já temos nossas funções auxiliares para indexação podemos popular nossa matriz de transferência, para isso iremos definir:\n",
    "\n",
    "**Importância de um nó (k)**: Quantidade de arestas (com peso diferente de zero) que saem do nó.\n",
    "\n",
    "**Transferência de importância**: Cada nó origem qualquer *X* transfere **1/k** de importância para cada um de seus nós destino. Em termos estatísticos, existe uma probabilidade **1/k** de que um usuário navegando na página *X* visite qualquer uma das páginas que originam em *X*. \n",
    "\n",
    "Tendo em mente as definições acima seguimos a seguinte lógica para criar a matriz de transferência :\n",
    "\n",
    "Se existe um vértice **i** que aponta para um vértice **J** dizemos que \n",
    "\n",
    "1. *M[ J ][ i ] = 1 / d [ i ]* \n",
    "\n",
    "onde M é a nossa matriz de transferência e *d [ i ]* é a quantidade vértices para qual o vértice *i* aponta.\n",
    "\n",
    "Porém, como primeiro passo iremos apenas identificar as arestas do grafo e adicionar a nossa matriz com valor igual a **1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRank(PageRank):\n",
    "    def calcula_matriz_transferencia(self):\n",
    "        for index, row in self.data_frame.iterrows():\n",
    "            peso = row['peso']\n",
    "            if peso >= 8.0:\n",
    "                origem = int(row['origem'])\n",
    "                destino = int(row['destino'])\n",
    "\n",
    "                origem, destino = self.get_indice_origem_destino(origem, destino)\n",
    "                \n",
    "                if origem not in self.numero_de_links:\n",
    "                    self.numero_de_links[origem] = 0\n",
    "                self.numero_de_links[origem] += 1\n",
    "\n",
    "                self.matriz_transferencia[destino][origem] = 1.0\n",
    "\n",
    "        self.matriz_transferencia = self.matriz_transferencia\n",
    "        print(\"Matriz de transferência\")\n",
    "        print(self.matriz_transferencia)    \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizando a matriz e eliminando vértices 'sem saída'\n",
    "\n",
    "Agora que já temos nossa matriz cheia de 1s vamos normaliza-la aplicando a fórmula que foi mencionada acima. Existirá contudo um outro problema, observaremos que existirão colunas na nossa matriz cuja soma será **0**. Isso indica um 'beco sem saída', um vértice que não aponta para nenhum outro.\n",
    "\n",
    "De um ponto de vista estatístico: Anteriormente consideramos que a probabilidade de que um usuário em um nó qualquer visite uma página 'vizinha' é **1/k**. Porém quando um nó não possui arestas saindo dele, qual é essa probabilidade? O que fazer?\n",
    "\n",
    "Iremos substituir todos os elementos dessas colunas por **1 / N**, onde N é quantidade de nós do grafo, para indicar que agora existe uma probabilidade igual de a partir desse nó chegar a qualquer outro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRank(PageRank):\n",
    "    def normaliza_matriz_transferencia(self):\n",
    "        cols_to_fix = []\n",
    "\n",
    "        for i in range(len(self.matriz_transferencia)):\n",
    "            soma_coluna = 0\n",
    "            for j in range(len(self.matriz_transferencia[i])):\n",
    "                soma_coluna += self.matriz_transferencia[j][i]\n",
    "                if self.matriz_transferencia[j][i] == 1:\n",
    "                    self.matriz_transferencia[j][i] = 1.0/self.numero_de_links[i] ## Normaliza \n",
    "            \n",
    "             ## Temos um beco sem saida, devemos eliminar\n",
    "            if soma_coluna == 0:\n",
    "                cols_to_fix.append(i)\n",
    "\n",
    "         ## Eliminando os becos sem saída\n",
    "        for i in cols_to_fix:\n",
    "            for j in range(len(self.matriz_transferencia)):\n",
    "                self.matriz_transferencia[j][i] = float(1) / float(self.N)\n",
    "        print(\"Matriz de transferência normalizada e sem 'becos sem saída'\")\n",
    "        print(self.matriz_transferencia)\n",
    "        print()\n",
    "        self.matriz_transferencia = np.matrix(self.matriz_transferencia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculando a matriz de PageRank (Google Matrix)\n",
    "\n",
    "Antes de rodar o algoritmo PageRank em si existem mais um problema que precisa ser tratado:\n",
    "\n",
    "**Componentes desconexos**: Podem haver componentes desconexos em nosso grafo. Isso faria com que certas partes do grafo ficassem inacessíveis e afetaria também o resultado do algoritmo que acabaria por nos dar rankings imprecisos.\n",
    "\n",
    "Como resolver? Teleportar! Podemos adicionar ao nosso algoritmo um fator constante **p = 0.15** e dizemos que esta é a probabilidade de teleportar para uma página aleatória do nosso grafo quando estivermos em qualquer nó, mesmo que este não seja um nó solto ou esteja em um componente desconexo. Como as probabilidades devem somar **1** vamos dizer que **0.85** é a chance de de seguir uma aresta qualquer que origine do nó atual.\n",
    "\n",
    "É válido notar que essa abordagem **converge** ou seja, todos os vértices são visitados em algum momento.\n",
    "\n",
    "Implementando essa idéia iremos obter uma Google Matrix *M* da forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture3/Images/M.GIF\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture3/Images/M.GIF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Onde *A* é a nossa matriz de transferência, *p* é a probabilidade de teleporte e *B* é uma matriz de 1s multiplicada por 1/total de nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRank(PageRank):\n",
    "\n",
    "    def get_google_matrix(self):\n",
    "        prob_teleport = 0.15\n",
    "\n",
    "        aux_matriz = (float(1) / float(self.N)) * np.ones((self.N, self.N))\n",
    "\n",
    "        self.google_matriz = (1 - prob_teleport) * self.matriz_transferencia + prob_teleport * aux_matriz\n",
    "        print('Google Matrix')\n",
    "        print(self.google_matriz)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rodando o algoritmo\n",
    "\n",
    "Iniciamos a variável *rank_vector* que irá guardar nossa resposta final com tamanho N (onde N é o número de nós) e cada nó inicia com valor igual a **1/N**. Ao decorrer das iterações do algoritmo esse vetor será multiplicado múltiplas vezes pela nossa *Google Matrix* e os valores nele presentes irão gradualmente mudando, até que a diferença nesses valores sejam tão pequenas que não valha mais a pena continuar iterando. O erro máximo que vamos aceitar é de **0.001**.\n",
    "\n",
    "Vale salientar ainda que o *rank_vector* é uma distribuição de probabilidades e a soma de seus valores deve ser igual a **1**, para verificar isto faremos algumas verificações mais abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PageRank(PageRank):\n",
    "    def get_page_rank(self, rank_vector = None, n_iter=0, maxerro = 0.001, pages_to_return=5):\n",
    "\n",
    "        if(rank_vector is None):\n",
    "            print('Iniciando Algoritmo PageRank...')\n",
    "            rank_vector = (float(1) / float(self.N)) * np.ones((self.N, 1))\n",
    "\n",
    "        n_iter += 1\n",
    "\n",
    "        if sum(abs(self.google_matriz * rank_vector - rank_vector)) > maxerro:\n",
    "            return self.get_page_rank(self.google_matriz * rank_vector, n_iter)\n",
    "        else:\n",
    "            print(\"Finish! Algoritmo convergiu com {0} iterações para um erro máximo de {1}.\".format(n_iter, maxerro))\n",
    "            print()\n",
    "\n",
    "            result = self.google_matriz * rank_vector\n",
    "            result_array = np.array([element[0] for element in np.asarray(result)])\n",
    "            posicao = 1\n",
    "\n",
    "            print(\"Sanity check. A soma das probabilidades deve ser 1, obtivemos: {0}\".format(sum([element[0] for element in np.asarray(result)])))\n",
    "            print()\n",
    "\n",
    "            for indice in result_array.argsort()[-pages_to_return:][::-1]:\n",
    "                print(\"{0}. Vértice id {1} com PageRank {2}\".format(posicao, self.indice_original[indice], result_array[indice]))\n",
    "                posicao += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Por fim podemos testar o algoritmo e verificar quais vértices possuem o maior PageRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de transferência\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      "Matriz de transferência normalizada e sem 'becos sem saída'\n",
      "[[0.        0.0010929 0.        ... 0.0010929 0.        0.       ]\n",
      " [0.2       0.0010929 0.        ... 0.0010929 0.        0.       ]\n",
      " [0.2       0.0010929 0.        ... 0.0010929 0.        0.       ]\n",
      " ...\n",
      " [0.        0.0010929 0.        ... 0.0010929 0.        0.       ]\n",
      " [0.        0.0010929 0.        ... 0.0010929 0.        0.       ]\n",
      " [0.        0.0010929 0.        ... 0.0010929 0.        0.       ]]\n",
      "\n",
      "Google Matrix\n",
      "[[1.63934426e-04 1.09289617e-03 1.63934426e-04 ... 1.09289617e-03\n",
      "  1.63934426e-04 1.63934426e-04]\n",
      " [1.70163934e-01 1.09289617e-03 1.63934426e-04 ... 1.09289617e-03\n",
      "  1.63934426e-04 1.63934426e-04]\n",
      " [1.70163934e-01 1.09289617e-03 1.63934426e-04 ... 1.09289617e-03\n",
      "  1.63934426e-04 1.63934426e-04]\n",
      " ...\n",
      " [1.63934426e-04 1.09289617e-03 1.63934426e-04 ... 1.09289617e-03\n",
      "  1.63934426e-04 1.63934426e-04]\n",
      " [1.63934426e-04 1.09289617e-03 1.63934426e-04 ... 1.09289617e-03\n",
      "  1.63934426e-04 1.63934426e-04]\n",
      " [1.63934426e-04 1.09289617e-03 1.63934426e-04 ... 1.09289617e-03\n",
      "  1.63934426e-04 1.63934426e-04]]\n",
      "\n",
      "Iniciando Algoritmo PageRank...\n",
      "Finish! Algoritmo convergiu com 22 iterações para um erro máximo de 0.001.\n",
      "\n",
      "Sanity check. A soma das probabilidades deve ser 1, obtivemos: 1.0000000000000169\n",
      "\n",
      "1. Vértice id 1 com PageRank 0.020114075236695\n",
      "2. Vértice id 25 com PageRank 0.012128212156843803\n",
      "3. Vértice id 4172 com PageRank 0.009786076992454163\n",
      "4. Vértice id 2642 com PageRank 0.009620837707382248\n",
      "5. Vértice id 1018 com PageRank 0.007559324150170568\n"
     ]
    }
   ],
   "source": [
    "## Testando o algorimo PageRank\n",
    "x = PageRank()\n",
    "x.calcula_matriz_transferencia()\n",
    "x.normaliza_matriz_transferencia()\n",
    "x.get_google_matrix()\n",
    "x.get_page_rank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizando os resultados com Gephi\n",
    "\n",
    "Visualizando o resultado com o Gephi fica evidente que os nós com maior PageRank parecem estar no 'meio'do grafo e tem bastante conexões de entrada e saída com vários outros nós, vejamos:\n",
    "\n",
    "![title](visu_ri_final.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusões\n",
    "\n",
    "Caso eu fosse um investidor em bitcoins eu poderia usar essas informações para determinar quem seriam as pessoas ou organizações mais confiáveis e realizar transações com um nível maior de certeza de que não seria vítima de uma fraude/golpe."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
